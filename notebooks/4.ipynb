{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from datasets import load_dataset\\ndataset = load_dataset(\"wmt17\", \"de-en\", split=\"train[:1%]\") \\n\\n\\nfor example in dataset[\\'translation\\']:\\n    print(example[\\'de\\']) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from datasets import load_dataset\n",
    "dataset = load_dataset(\"wmt17\", \"de-en\", split=\"train[:1%]\") \n",
    "\n",
    "\n",
    "for example in dataset['translation']:\n",
    "    print(example['de']) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanneswidera/Uni/Master/Semester 3/Transformer/transformer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from src.utils.data_cleaning import clean_dataset\n",
    "from src.modelling.tokenizer import CustomBPETokenizer\n",
    "from src.dataset import TranslationDataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"wmt17\", \"de-en\", split=\"train[:1%]\") \n",
    "cleaned_data = clean_dataset(dataset)\n",
    "# Initialize and use the tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = CustomBPETokenizer(cleaned_data, vocab_size=50000, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Tokenizer(name_or_path='/Users/hanneswidera/Uni/Master/Semester 3/Transformer/transformer/storage/gpt2_from_bpe', vocab_size=50000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t50000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"[BOS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.', 'en': 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.', 'src': 'ich erkläre die am freitag, dem 17. dezember unterbrochene sitzungsperiode des europäischen parlaments für wiederaufgenommen, wünsche ihnen nochmals alles gute zum jahreswechsel und hoffe, daß sie schöne ferien hatten.', 'tgt': 'i declare resumed the session of the european parliament adjourned on friday 17 december 1999, and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'}\n",
      "Tokens: ['ich', 'ĠerklÃ¤re', 'Ġdie', 'Ġam', 'Ġfreitag', ',', 'Ġdem', 'Ġ17', '.', 'Ġdezember', 'Ġunterb', 'ro', 'che', 'ne', 'Ġsitzungsperiode', 'Ġdes', 'ĠeuropÃ¤ische', 'n', 'Ġparl', 'ame', 'n', 'ts', 'ĠfÃ¼r', 'Ġwiederauf', 'ge', 'n', 'omme', 'n', ',', 'ĠwÃ¼nsche', 'Ġih', 'ne', 'n', 'Ġnochmals', 'Ġalles', 'Ġgute', 'Ġzum', 'Ġjahres', 'wechsel', 'Ġund', 'Ġhoffe', ',', 'ĠdaÃŁ', 'Ġsie', 'ĠschÃ¶ne', 'Ġfer', 'ie', 'n', 'Ġhatte', 'n', '.']\n",
      "Encoded: [85, 15850, 107, 397, 6212, 11, 264, 4469, 13, 6101, 3885, 99, 640, 311, 12905, 232, 774, 43, 299, 963, 43, 265, 221, 4328, 143, 43, 30655, 43, 11, 7759, 466, 311, 43, 5001, 2607, 3180, 573, 2721, 16052, 129, 2394, 11, 207, 294, 19686, 5903, 83, 43, 2929, 43, 13]\n",
      "Decoded: ich erkläre die am freitag, dem 17. dezember unterbrochene sitzungsperiode des europäischen parlaments für wiederaufgenommen, wünsche ihnen nochmals alles gute zum jahreswechsel und hoffe, daß sie schöne ferien hatten.\n",
      "_______\n",
      "Tokens: ['i', 'Ġdeclare', 'Ġresumed', 'Ġthe', 'Ġsession', 'Ġof', 'Ġthe', 'Ġeuropean', 'Ġparl', 'i', 'ame', 'nt', 'Ġadjourned', 'Ġon', 'Ġfriday', 'Ġ17', 'Ġdecember', 'Ġ1999', ',', 'Ġand', 'Ġi', 'Ġwould', 'Ġlike', 'Ġonce', 'Ġagain', 'Ġto', 'Ġwish', 'Ġyou', 'Ġa', 'Ġhappy', 'Ġnew', 'Ġyear', 'Ġin', 'Ġthe', 'Ġhope', 'Ġthat', 'Ġyou', 'Ġe', 'n', 'j', 'oy', 'ed', 'Ġa', 'Ġpleasant', 'Ġfest', 'ive', 'Ġperiod', '.']\n",
      "Encoded: [38, 11086, 10392, 79, 7319, 113, 79, 327, 299, 38, 963, 28423, 15588, 183, 5831, 4469, 5962, 1584, 11, 125, 116, 391, 570, 2186, 834, 112, 1796, 496, 69, 6072, 734, 752, 91, 79, 1436, 160, 496, 87, 43, 39, 1016, 128, 69, 32125, 970, 272, 2526, 13]\n",
      "Decoded: i declare resumed the session of the european parliament adjourned on friday 17 december 1999, and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "{'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'src': 'wie sie feststellen konnten, ist der gefürchtete millenium-bug  nicht eingetreten. doch sind bürger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden.', 'tgt': 'although, as you will have seen, the dreaded millennium bug failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.'}\n",
      "Tokens: ['wie', 'Ġsie', 'Ġfeststelle', 'n', 'Ġkonnte', 'n', ',', 'Ġist', 'Ġder', 'ĠgefÃ¼r', 'chtete', 'Ġmille', 'n', 'ium', '-', 'b', 'ug', 'Ġ', 'Ġnicht', 'Ġeinget', 'rete', 'n', '.', 'Ġdoch', 'Ġsind', 'ĠbÃ¼rger', 'Ġeiniger', 'Ġunserer', 'Ġmitglied', 'sta', 'ate', 'n', 'Ġopfer', 'Ġvon', 'Ġschreckliche', 'n', 'Ġnaturkatastrophe', 'n', 'Ġgewor', 'de', 'n', '.']\n",
      "Encoded: [980, 294, 42587, 43, 5376, 43, 11, 225, 114, 36688, 49943, 42970, 43, 1687, 12, 31, 328, 62, 234, 12845, 3185, 43, 13, 1082, 369, 1379, 5045, 1246, 676, 562, 273, 43, 4410, 220, 20290, 43, 31496, 43, 5025, 196, 43, 13]\n",
      "Decoded: wie sie feststellen konnten, ist der gefürchtete millenium-bug  nicht eingetreten. doch sind bürger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden.\n",
      "_______\n",
      "Tokens: ['alth', 'ough', ',', 'Ġas', 'Ġyou', 'Ġwill', 'Ġhave', 'Ġsee', 'n', ',', 'Ġthe', 'Ġdread', 'ed', 'Ġmille', 'nn', 'ium', 'Ġbug', 'Ġfailed', 'Ġto', 'Ġmaterialise', ',', 'Ġstill', 'Ġthe', 'Ġpeople', 'Ġin', 'Ġa', 'Ġnumber', 'Ġof', 'Ġcountries', 'Ġsuffered', 'Ġa', 'Ġseries', 'Ġof', 'Ġnatural', 'Ġdisasters', 'Ġthat', 'Ġtruly', 'Ġwere', 'Ġdreadful', '.']\n",
      "Encoded: [1585, 1315, 11, 211, 496, 295, 261, 1056, 43, 11, 79, 16346, 128, 42970, 36111, 1687, 41085, 7335, 112, 27513, 11, 1401, 79, 786, 91, 69, 1503, 113, 707, 9213, 69, 7064, 113, 5146, 7266, 160, 7496, 1052, 17579, 13]\n",
      "Decoded: although, as you will have seen, the dreaded millennium bug failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer \n",
    "def tokenizer_test(example):\n",
    "    tokens = tokenizer.tokenize(example)\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    encoded = tokenizer.encode(example)\n",
    "    print(\"Encoded:\", encoded)\n",
    "\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    print(\"Decoded:\", decoded)\n",
    "    \n",
    "    \n",
    "for example in cleaned_data[:2]:\n",
    "    print(example)\n",
    "    tokenizer_test(example['src'])\n",
    "    print(\"_______\")\n",
    "    tokenizer_test(example['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src_input_ids': tensor([[   1,   78,  126,  ...,    0,    0,    0],\n",
      "        [   1,  407, 1426,  ...,    0,    0,    0],\n",
      "        [   1,   42,  387,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  252,   77,  ...,    0,    0,    0],\n",
      "        [   1,  268,  395,  ...,    0,    0,    0],\n",
      "        [   1,  252,   77,  ...,    0,    0,    0]]), 'tgt_input_ids': tensor([[   78,   126,   806,  ...,     0,     0,     0],\n",
      "        [  407,  1426,   186,  ...,     0,     0,     0],\n",
      "        [   42,   387,   149,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  252,    77,   126,  ...,     0,     0,     0],\n",
      "        [  268,   395,  1052,  ...,     0,     0,     0],\n",
      "        [  252,    77, 29336,  ...,     0,     0,     0]])}\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import TranslationDataset\n",
    "\n",
    "translation_dataset = TranslationDataset(cleaned_data, tokenizer)\n",
    "\n",
    "dataloader = DataLoader(translation_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "first_batch = next(iter(dataloader))\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding + Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "import torch\n",
    "from src.modelling.positional_encoding import PositionalEncoding\n",
    "from src.modelling.word_embedding import WordEmbedding\n",
    "\n",
    "\n",
    "vocab_size = 50000\n",
    "d_model = 512\n",
    "max_len = 64\n",
    "\n",
    "# Initialize layers\n",
    "word_embedding = WordEmbedding(vocab_size, d_model)\n",
    "positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "# Example input (batch_size, sequence_length)\n",
    "input_ids = torch.randint(0, vocab_size, (32, max_len))\n",
    "\n",
    "# Apply word embedding and positional encoding\n",
    "embedded = word_embedding(input_ids)\n",
    "encoded = positional_encoding(embedded)\n",
    "\n",
    "print(encoded.shape)  # Output: torch.Size([32, 100, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the DataLoader to get batches of data\n",
    "for batch in dataloader:\n",
    "    input_ids = batch[\"src_input_ids\"]\n",
    "    target_ids = batch[\"tgt_input_ids\"]\n",
    "\n",
    "    # Apply word embedding and positional encoding\n",
    "    embedded = word_embedding(input_ids)\n",
    "    encoded = positional_encoding(embedded)\n",
    "\n",
    "    # batchsize x max_length x embedding size\n",
    "    print(encoded.shape)  # Output: torch.Size([32, 64, 512])\n",
    "    break  # Remove this break to process all batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
