{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71eafa2401a2e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementing Transformer Models\n",
    "## Practical I\n",
    "Carel van Niekerk & Hsien-Chin Lin\n",
    "\n",
    "7-11.10.2024\n",
    "\n",
    "---\n",
    "\n",
    "In this practical, we will set up a python project for implementing a deep learning model, and explore the basics of the transformer model namely, embedding input sequences and the attention mechanism. We will focus on creating a modular codebase which makes it easy to debug, adapt and reuse the code. We will also set up a python environment for the project, making it easy to manage the project dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d36750b236514",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Setting up Environment\n",
    "We will use Python 3.10 or above for this course. If you have not installed Python yet, you can download it from [here](https://www.python.org/downloads/). We recommend using the latest version of Python. If you are using Windows, make sure to select the option to add Python to your PATH variable during the installation process. This will allow you to run Python from the command line.\n",
    "\n",
    "#### 1.1 Installing an IDE\n",
    "We recommend using an IDE (Integrated Development Environment) for this course. An IDE is a software application that provides comprehensive facilities to computer programmers for software development. We recommend using [VSCode](https://code.visualstudio.com/). VSCode is a cross-platform IDE that provides smart code completion, code inspections, on-the-fly error highlighting and quick-fixes, along with automated code refactorings and rich navigation capabilities. VSCode also provides support for version control systems, Python web frameworks, databases, and scientific tools.\n",
    "\n",
    "#### 1.2 Installing Git\n",
    "We will use Git for version control. Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. You can download Git from [here](https://git-scm.com/downloads). If you are using Windows, make sure to select the option to add Git to your PATH variable during the installation process. This will allow you to run Git from the command line.\n",
    "\n",
    "#### 1.4 Creating a virtual environment\n",
    "Before we start installing the project dependencies, we will create a virtual environment for the project. A virtual environment is a tool that helps to keep dependencies required by different projects separate by creating isolated python virtual environments for them. This is one of the most important tools that most of the Python developers use. We will use the `poetry` package to create a virtual environment for our project. You can install the `poetry` package using the following command:\n",
    "\n",
    "```bash\n",
    "pip install poetry\n",
    "```\n",
    "\n",
    "To create a virtual environment, you must specify a path. For example to create one in the local directory called 'transformer', type the following:\n",
    "\n",
    "```bash\n",
    "poetry config virtualenvs.in-project true\n",
    "poetry new transformer\n",
    "```\n",
    "\n",
    "And follow the setup instructions.\n",
    "\n",
    "Then run:\n",
    "\n",
    "```bash\n",
    "cd transformer\n",
    "poetry install\n",
    "```\n",
    "\n",
    "This will create a virtual environment in the directory you specified. The virtual environment will be created in a directory called `transformer_project`.\n",
    "\n",
    "To begin using the virtual environment, it needs to be activated:\n",
    "\n",
    "```bash\n",
    "poetry shell\n",
    "```\n",
    "You can confirm youâ€™re in the virtual environment by checking the location of your Python interpreter (`which python`), it should point to the env directory.\n",
    "\n",
    "#### 1.5 Installing project dependencies\n",
    "\n",
    "For this project we will use the following packages:\n",
    "- [PyTorch](https://pytorch.org/)\n",
    "- [PyTest](https://docs.pytest.org/en/stable/) (some standard tests will be provided to test important modules)\n",
    "- Huggingface datasets (optionally you can download the dataset manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65725cb5fcba5e10",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Setting up the project\n",
    "\n",
    "#### 2.1 Creating a project directory\n",
    "\n",
    "We will create a directory for the project. This directory will contain all the code for the project. We will call this directory `transformer_project`. You can create this directory in the location of your choice. For example, you can create it in your project directory.\n",
    "\n",
    "#### 2.2 How to structure the project\n",
    "\n",
    "There are many ways to structure a deep learning project. We will use a modular approach, where we will create a separate python module for each component of the project. This will make it easy to debug, adapt and reuse the code. We will create the following modules (directories/scripts) for our project:\n",
    "\n",
    "- `modelling`: This module will contain the code for the model architecture including the learning rate schedulers, loss functions and training code.\n",
    "- `dataset.py`: This script will contain the code for loading, cleaning and preparing the data for model training.\n",
    "- `test`: This directory will contain the code for testing the modules.\n",
    "- `run/main.py`: This script will contain the code for running the model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15f16f51b3c92a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Install all required packages for the project.\n",
    "2. Create a virtual environment for the project.\n",
    "3. Setup a project directory.\n",
    "4. Push your clean project to GitLab.\n",
    "5. Study the [tutorial](https://vgel.me/posts/handmade-transformer/), up to the end of the section on designing the attention head. (Feel free to use the [Attention is all you need](https://arxiv.org/abs/1706.03762) paper as an extra resource)\n",
    "6. Make sure you are understand the embeddings of the input. Explain why we need the position of input characters in the embedding.\n",
    "7. Implement the attention mechanism. Please implement the attention mechanism as a pytorch module as you will need this later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d1aae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5317ca6a18b44b1f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We need positional information in embeddings because embeddings alone capture the meaning of individual characters or tokens but not their order. In tasks like language processing, the sequence of characters or words matters, as changing the order can change the meaning. Since models like transformers process inputs in parallel (not sequentially), they need positional embeddings to know the correct order of the inputs. This allows the model to understand both the content and its position within the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fe475",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
